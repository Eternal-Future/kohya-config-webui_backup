{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP62JpBpGuo9dwi5LI/mwd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WSH032/kohya-config-webui/blob/main/kohya_train_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| ![visitors](https://visitor-badge.glitch.me/badge?page_id=wsh.kohya_train_webui) | [![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)</a> |"
      ],
      "metadata": {
        "id": "ll6PRAEKIfjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(一)完成材料下载"
      ],
      "metadata": {
        "id": "Led8SgZ0YnGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**（确保你用的是GPU运行时）**挂载谷歌硬盘,克隆kohya的库\n",
        "\n",
        "#挂载谷歌硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!echo \"google硬盘挂载完成.\"\n",
        "\n",
        "!pip install gradio > /dev/null 2>&1\n",
        "#安装aria2\n",
        "!apt -qq install liblz4-tool aria2  > /dev/null 2>&1\n",
        "#@title 克隆kohya的库 \n",
        "%cd /content\n",
        "!git clone https://github.com/kohya-ss/sd-scripts.git"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sGDquRQCOMzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####拷贝材料(支持重复训练时选择新的路径)\n",
        "\n",
        "\n",
        "#@markdown 训练集在`/content/train/data`\n",
        "\n",
        "#@markdown 正则化在`/content/train/reg`\n",
        "\n",
        "#@markdown 是否使用自定义路径，是否拷贝正则化图片\n",
        "use_data_dir_self = False #@param {type:\"boolean\"}\n",
        "copy_reg = False #@param {type:\"boolean\"}\n",
        "#@markdown 自定义训练集路径，正则化集路径（仅在勾选后有效）**（不要使用带空格、中文的路径）**\n",
        "train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\" #@param {type:'string'}\n",
        "reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\" #@param {type:'string'}\n",
        "\n",
        "train_data_dir = \"/content/train/data\"\n",
        "reg_data_dir = \"/content/train/reg\"\n",
        "\n",
        "if use_data_dir_self:\n",
        "  print(f\"你使用的是自定义路径\")\n",
        "else:\n",
        "  train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\"\n",
        "  reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\"\n",
        "  print(f\"你使用的是默认路径\")\n",
        "print(f\"训练集地址为:{train_data_dir_self}\")\n",
        "\n",
        "#删除之前的训练材料\n",
        "!mkdir -p /content/lora-scripts/train/  #防止首次运行报错\n",
        "!rm -r /content/lora-scripts/train/\n",
        "\n",
        "#从谷歌硬盘中拷贝你之前上传的训练材料\n",
        "print(\"拷贝训练集中\")\n",
        "!mkdir -p {train_data_dir}\n",
        "!cp -r {train_data_dir_self}/* {train_data_dir}\n",
        "!echo \"copy训练材料完成.\"\n",
        "\n",
        "if copy_reg:\n",
        "  #拷贝正则化图片\n",
        "  print(f\"正则化集地址为:{reg_data_dir_self}\")\n",
        "  print(\"拷贝正则化集中\")\n",
        "  !mkdir -p {reg_data_dir}\n",
        "  !cp -r {reg_data_dir_self}/* {reg_data_dir}\n",
        "  !echo \"copy正则化图片完成.\"\n",
        "else:\n",
        "  print(\"不拷贝正则化集\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EzHADOPZMlN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 下载模型\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "\n",
        "#@markdown **下载地址在`/content/sd-models/`**\n",
        "#@markdown **可以反复下载多个模型，别把磁盘搞满就行**\n",
        "\n",
        "#@markdown SD1.x model\n",
        "modelName = \"Animefull-final-pruned\"  # @param [\"\", \"Animefull-final-pruned\", \"Stable-Diffusion-v1-5\", \"Anything-v3-1\", \"AnyLoRA\", \"AnimePastelDream\", \"Chillout-mix\", \"OpenJourney-v4\"]\n",
        "#@markdown SD2.x model\n",
        "v2ModelName = \"\"  # @param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"plat-diffusion-v1-3-1\", \"replicant-v1\", \"illuminati-diffusion-v1-0\", \"illuminati-diffusion-v1-1\", \"waifu-diffusion-1-4-anime-e2\", \"waifu-diffusion-1-5-e2\", \"waifu-diffusion-1-5-e2-aesthetic\"]\n",
        "\n",
        "#@markdown **自定义模型链接例如`https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/novelailatest-pruned.ckpt`**\n",
        "\n",
        "#@markdown **或者自定义模型路径例如`/content/drive/MyDrive/Lora/model/your_model.ckpt`**\n",
        "\n",
        "\n",
        "\n",
        "base_model_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "base_model_self_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "base_model_extension = \"ckpt\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
        "\n",
        "\n",
        "modelUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "    \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "    \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "]\n",
        "modelList = [\n",
        "    \"\",\n",
        "    \"Animefull-final-pruned\",\n",
        "    \"Anything-v3-1\",\n",
        "    \"AnyLoRA\",\n",
        "    \"AnimePastelDream\",    \n",
        "    \"Chillout-mix\",\n",
        "    \"OpenJourney-v4\",\n",
        "    \"Stable-Diffusion-v1-5\",\n",
        "]\n",
        "v2ModelUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n",
        "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
        "    \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n",
        "    \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n",
        "    \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n",
        "    \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n",
        "]\n",
        "v2ModelList = [\n",
        "    \"\",\n",
        "    \"stable-diffusion-2-1-base\",\n",
        "    \"stable-diffusion-2-1-768v\",\n",
        "    \"plat-diffusion-v1-3-1\",\n",
        "    \"replicant-v1\",\n",
        "    \"illuminati-diffusion-v1-0\",\n",
        "    \"illuminati-diffusion-v1-1\",\n",
        "    \"waifu-diffusion-1-4-anime-e2\",\n",
        "    \"waifu-diffusion-1-5-e2\",\n",
        "    \"waifu-diffusion-1-5-e2-aesthetic\",\n",
        "]\n",
        "if modelName:\n",
        "    installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "if v2ModelName:\n",
        "    installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "\n",
        "#下载路径\n",
        "base_model_dir = \"/content/sd-models/\"\n",
        "\n",
        "#检查连接是否含有扩展名信息，不含有则由用户指定\n",
        "def check_ext(url):\n",
        "  if url.endswith(\".ckpt\"):\n",
        "    return \"ckpt\"\n",
        "  elif url.endswith(\".safetensors\"):\n",
        "    return \"safetensors\"\n",
        "  else:\n",
        "    return base_model_extension\n",
        "#下载模型\n",
        "def install(checkpoint_name, url):\n",
        "    ext = check_ext(url)\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {checkpoint_name}.{ext} {url}\n",
        "    return f\"{checkpoint_name}.{ext}\"   #返回模型名称\n",
        "def install_checkpoint():\n",
        "    for model in installModels:\n",
        "        return install(model[0], model[1])\n",
        "    for v2model in installv2Models:\n",
        "        return install(v2model[0], v2model[1])\n",
        "\n",
        "#尝试下载预设模型\n",
        "base_model_name = install_checkpoint()\n",
        "#预设下载成功，则完成路径修改\n",
        "if base_model_name:\n",
        "  pretrained_model = base_model_dir + base_model_name\n",
        "#下载失败，base_model_name为non\n",
        "else:\n",
        "  #不留空，则尝试用连接下载\n",
        "  if base_model_url:\n",
        "    base_model_name = \"download.\" + check_ext(base_model_url)\n",
        "    pretrained_model = base_model_dir + base_model_name\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {base_model_name} --allow-overwrite {base_model_url}\n",
        "  #留空，将考虑从自定义路径中拷贝\n",
        "  else:\n",
        "    if base_model_self_dir:\n",
        "      base_model_name = \"self.\" + check_ext(base_model_self_dir)\n",
        "      pretrained_model = base_model_dir + base_model_name\n",
        "      !cp {base_model_self_dir} {pretrained_model}\n",
        "    else:\n",
        "      print(\"你根本没选择任何模型！\")\n",
        "\n",
        "\n",
        "#输出模型信息\n",
        "print(f\"你选择的是: {base_model_name} 模型\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OYGUN309MuUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##  下载vae（可选）\n",
        "\n",
        "#@markdown **下载地址在`/content/vae/`**\n",
        "\n",
        "#储存下载信息参数\n",
        "installVae = []\n",
        "#@markdown 选择 `none` 意味着不使用vae\n",
        "\n",
        "#@markdown 选择一个Vae下载并使用`\"animevae.pt\", \"kl-f8-anime.ckpt\", \"vae-ft-mse-840000-ema-pruned.ckpt\"`\n",
        "\n",
        "vaeUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "]\n",
        "vaeList = [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"none\"  # @param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "#开始下载\n",
        "vae_dir = \"/content/vae/\"\n",
        "def install(vae_name, url):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --allow-overwrite --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vae_dir} -o \"vae.pt\" \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "    if vaeName != \"none\":\n",
        "        for vae in installVae:\n",
        "            install(vae[0], vae[1])\n",
        "    else:\n",
        "        pass\n",
        "install_vae()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hiA3z5rPNriX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(二)设置参数\n"
      ],
      "metadata": {
        "id": "mAeB_J7sYrmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title WebUI设置参数\n",
        "\n",
        "#@markdown **使用方法，运行代码块后，打开输出的连接用另一个网页操作更方便，除了下方给出的参数你要按着填，其余的在WebUI里设置就行**`小贴士:你打开WebUI后，就可以直接运行下面安装依赖环境那一步，安装和参数设置可以同时进行,WebUI会一直在后台`\n",
        "\n",
        "#@markdown 写入文件夹 `/content/sd-scripts`\n",
        "\n",
        "#@markdown train_data_dir `/content/train/data`\n",
        "\n",
        "#@markdown reg_data_dir（可选） `/content/train/reg`\n",
        "\n",
        "#@markdown 底模文件夹地址 `/content/sd-models`\n",
        "\n",
        "#@markdown 使用vae(可选) `/content/vae`\n",
        "\n",
        "#@markdown 模型、log日志输出地址 `按自己想保存的地方填`\n",
        "\n",
        "import os\n",
        "import toml\n",
        "import warnings\n",
        "import gradio as gr\n",
        "\n",
        "common_parameter_dict_key_list=[]\n",
        "sample_parameter_dict_key_list=[]\n",
        "plus_parameter_dict_key_list=[]\n",
        "\n",
        "common_parameter_dict=({})\n",
        "sample_parameter_dict=({})\n",
        "plus_parameter_dict=({})\n",
        "\n",
        "random_symbol = '\\U0001f3b2\\ufe0f'  # 🎲️\n",
        "reuse_symbol = '\\u267b\\ufe0f'  # ♻️\n",
        "paste_symbol = '\\u2199\\ufe0f'  # ↙\n",
        "refresh_symbol = '\\U0001f504'  # 🔄\n",
        "save_style_symbol = '\\U0001f4be'  # 💾\n",
        "apply_style_symbol = '\\U0001f4cb'  # 📋\n",
        "clear_prompt_symbol = '\\U0001f5d1\\ufe0f'  # 🗑️\n",
        "extra_networks_symbol = '\\U0001F3B4'  # 🎴\n",
        "switch_values_symbol = '\\U000021C5' # ⇅\n",
        "folder_symbol = '\\U0001f4c2'  # 📂\n",
        "\n",
        "parameter_len_dict={\"common\":0, \"sample\":0, \"plus\":0}\n",
        "\n",
        "def check_len_and_2dict(args, parameter_len_dict_value, parameter_dict_key_list, func_name=\"\"):\n",
        "    if len(args) != parameter_len_dict_value:\n",
        "        warnings.warn(f\"传入{func_name}的参数长度不匹配\", UserWarning)\n",
        "    if len(parameter_dict_key_list) != parameter_len_dict_value:\n",
        "        warnings.warn(f\" {func_name}内部字典赋值关键字列表的长度不匹配\", UserWarning)\n",
        "    parameter_dict = dict(zip(parameter_dict_key_list, args))\n",
        "    return parameter_dict\n",
        "\n",
        "def common_parameter_get(*args):\n",
        "    global common_parameter_dict\n",
        "    common_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"common\"], common_parameter_dict_key_list, func_name=\"common_parameter_get\")\n",
        "    common_parameter_toml = toml.dumps(common_parameter_dict)\n",
        "    common_parameter_title = \"基础参数配置确认\"\n",
        "    return common_parameter_toml,  common_parameter_title\n",
        "\n",
        "def sample_parameter_get(*args):\n",
        "    global sample_parameter_dict\n",
        "    sample_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"sample\"], sample_parameter_dict_key_list, func_name=\"sample_parameter_get\")\n",
        "    sample_parameter_toml = toml.dumps(sample_parameter_dict)\n",
        "    sample_parameter_title = \"采样配置确认\"\n",
        "    return sample_parameter_toml,  sample_parameter_title\n",
        "\n",
        "\n",
        "def plus_parameter_get(*args):\n",
        "    global plus_parameter_dict\n",
        "    plus_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"plus\"], plus_parameter_dict_key_list, func_name=\"plus_parameter_get\")\n",
        "    plus_parameter_toml = toml.dumps(plus_parameter_dict)\n",
        "    plus_parameter_title = \"进阶参数配置确认\"\n",
        "    return plus_parameter_toml,  plus_parameter_title\n",
        "\n",
        "\n",
        "def all_parameter_get(*args):\n",
        "    if len(args) != sum( parameter_len_dict.values() ):\n",
        "         warnings.warn(f\"传入all_parameter_get的参数长度不匹配\", UserWarning)\n",
        "    common_parameter_toml,  common_parameter_title = common_parameter_get( *args[ : parameter_len_dict[\"common\"] ] )\n",
        "    sample_parameter_toml,  sample_parameter_title = sample_parameter_get( *args[ parameter_len_dict[\"common\"] : parameter_len_dict[\"common\"] + parameter_len_dict[\"sample\"] ] )\n",
        "    plus_parameter_toml,  plus_parameter_title = plus_parameter_get( *args[ -parameter_len_dict[\"plus\"] : ] )\n",
        "    return common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  \"全部参数确认\"\n",
        "\n",
        "def model_get(model_dir):\n",
        "    model_dir = model_dir if model_dir else os.getcwd()\n",
        "    files = [f for f in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, f))]\n",
        "    if files:\n",
        "        return model_dir, gr.update( choices=files,value=files[0] )\n",
        "    else:\n",
        "        return model_dir, gr.update( choices=[],value=\"\" )\n",
        "\n",
        "def write_files(write_files_dir):\n",
        "    write_files_dir = write_files_dir if write_files_dir else os.getcwd()\n",
        "    os.makedirs(write_files_dir, exist_ok=True)\n",
        "    config_file_toml_path = os.path.join(write_files_dir, \"config_file.toml\")\n",
        "    sample_prompts_txt_path = os.path.join(write_files_dir, \"sample_prompts.txt\")\n",
        "\n",
        "    all = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}\n",
        "\n",
        "    def parameter2toml():\n",
        "\n",
        "        #生成config_file.toml的字典\n",
        "\n",
        "        #model_arguments部分\n",
        "        model_arguments = { key: all.get(key) for key in [\"v2\", \"v_parameterization\"] }\n",
        "        \"\"\" 生成底模路径 \"\"\"\n",
        "        base_model_path = os.path.join( all.get(\"base_model_dir\"), all.get(\"base_model_name\") )\n",
        "        model_arguments.update( {\"pretrained_model_name_or_path\": base_model_path} )\n",
        "        \"\"\" 生成vae路径 \"\"\"\n",
        "        if all.get(\"use_vae\"):\n",
        "            vae_model_path = os.path.join( all.get(\"vae_model_dir\"), all.get(\"vae_model_name\") )\n",
        "            model_arguments.update( {\"vae\": vae_model_path} )\n",
        "\n",
        "        #additional_network_arguments部分\n",
        "        additional_network_arguments = { key: all.get(key) for key in [\"unet_lr\", \"text_encoder_lr\", \"network_dim\",\\\n",
        "                                            \"network_alpha\", \"network_train_unet_only\",\\\n",
        "                                            \"network_train_text_encoder_only\"] }\n",
        "        \"\"\" 生成如network_module = \"locon.locon_kohya\" \"\"\"\n",
        "        #[\"LoRA-LierLa\", \"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\", \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]\n",
        "        #主要负责network_module的参数生成\n",
        "        def network_module_param(train_method):\n",
        "            conv_dim = all.get(\"conv_dim\") if train_method != \"DyLoRa-C3Lier\" else all.get(\"network_dim\")\n",
        "            conv_alpha = all.get(\"conv_alpha\")\n",
        "            algo = \"lora\" if train_method == \"LoCon_Lycoris\" else \"loha\"\n",
        "            unit = all.get(\"unit\")\n",
        "            if train_method in [\"LoRA-LierLa\", \"LoRA-C3Lier\"]:\n",
        "                network_module = \"networks.lora\"\n",
        "                if train_method == \"LoRA-C3Lier\":\n",
        "                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "                else:\n",
        "                    network_module_args = []\n",
        "            elif train_method in [\"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n",
        "                network_module = \"lycoris.kohya\"\n",
        "                network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"algo={algo}\"]\n",
        "            elif train_method in [\"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]:\n",
        "                network_module = \"networks.dylora\"\n",
        "                if train_method == \"DyLoRa-C3Lier\":\n",
        "                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"unit={unit}\"]\n",
        "                else:\n",
        "                    network_module_args = [f\"unit={unit}\"]\n",
        "            else: \n",
        "                warnings.warn(f\"训练方法参数生成出错\", UserWarning)\n",
        "            return network_module, network_module_args\n",
        "        network_module, network_module_args = network_module_param( all.get(\"train_method\") )\n",
        "        #更多network_args部分（主要为分层训练）\n",
        "        network_lr_weight_args = [ f\"{name}={all.get(name)}\" for name in [\"up_lr_weight\", \"mid_lr_weight\", \"down_lr_weight\"] if all.get(name) ]\n",
        "\n",
        "        def network_block_param(train_method):\n",
        "            lst = [\"block_dims\", \"block_alphas\", \"conv_block_dims\", \"conv_block_alphas\"]\n",
        "            if train_method == \"LoRA-LierLa\":\n",
        "                return [ f\"{name}={all.get(name)}\" for name in lst[0:1] if all.get(name) ]\n",
        "            if train_method in [\"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n",
        "                return [ f\"{name}={all.get(name)}\" for name in lst if all.get(name) ]\n",
        "            else:\n",
        "                return []\n",
        "        network_block_args = network_block_param( all.get(\"train_method\") )\n",
        "        \n",
        "\n",
        "        network_args = []\n",
        "        network_args.extend(network_module_args)\n",
        "        network_args.extend(network_lr_weight_args)\n",
        "        network_args.extend(network_block_args)\n",
        "\n",
        "        additional_network_arguments.update( { \"network_module\":network_module } )\n",
        "        additional_network_arguments.update( {\"network_args\":network_args} )          \n",
        "\n",
        "        #optimizer_arguments部分\n",
        "        optimizer_arguments = { key: all.get(key) for key in [\"optimizer_type\", \"lr_scheduler\", \"lr_warmup_steps\"] }\n",
        "        \"\"\"只有余弦重启调度器指定重启次数\"\"\"\n",
        "        if all.get(\"lr_scheduler\") == \"cosine_with_restarts\":\n",
        "            optimizer_arguments.update( {\"lr_restart_cycles\":all.get(\"lr_restart_cycles\")} )\n",
        "        \"\"\"学习率lr指定=unet_lr\"\"\"\n",
        "        optimizer_arguments.update( {\"learning_rate\":all.get(\"unet_lr\")} )\n",
        "            #optimizer_args（待添加）\n",
        "\n",
        "        #dataset_arguments部分\n",
        "        dataset_arguments = {\"cache_latents\":True,\n",
        "                    \"shuffle_caption\":True,\n",
        "                    \"enable_bucket\":True\n",
        "        }\n",
        "\n",
        "        #training_arguments部分\n",
        "        training_arguments = { key: all.get(key) for key in [\"batch_size\", \"noise_offset\", \"keep_tokens\",\\\n",
        "                                      \"min_bucket_reso\", \"max_bucket_reso\",\\\n",
        "                                      \"caption_extension\", \"max_token_length\", \"seed\",\\\n",
        "                                      \"xformers\", \"lowram\"]\n",
        "        }\n",
        "        \"\"\"min_snr_gamma大于零才生效\"\"\"\n",
        "        if all.get(\"min_snr_gamma\") > 0:\n",
        "            training_arguments.update( { \"min_snr_gamma\":all.get(\"min_snr_gamma\") } )\n",
        "        \"\"\" 最大训练时间 \"\"\"\n",
        "        training_arguments.update( { all.get(\"max_train_method\"):all.get(\"max_train_value\") } )\n",
        "        \"\"\" 训练分辨率 \"\"\"\n",
        "        training_arguments.update( { \"resolution\":f\"{all.get('width')},{all.get('height')}\" } )\n",
        "        \"\"\" 如果v2开启，则不指定clip_skip \"\"\"\n",
        "        if not all.get(\"v2\"):\n",
        "            training_arguments.update( { \"clip_skip\":all.get(\"clip_skip\") } )\n",
        "        \"\"\" 重训练模块 \"\"\"\n",
        "        if all.get(\"use_retrain\") == \"model\":\n",
        "            training_arguments.update( { \"network_weights\":all.get(\"retrain_dir\") } )\n",
        "        elif all.get(\"use_retrain\") == \"state\":\n",
        "            training_arguments.update( { \"resume\":all.get(\"retrain_dir\") } )\n",
        "        \"\"\"  训练精度、保存精度 \"\"\"\n",
        "        training_arguments.update( { \"mixed_precision\":\"fp16\" } )\n",
        "        training_arguments.update( { \"save_precision\":\"fp16\" } )\n",
        "        \n",
        "\n",
        "\n",
        "        #sample_prompt_arguments部分（采样间隔，采样文件地址待添加）\n",
        "        sample_prompt_arguments = { key: all.get(key) for key in [\"sample_sampler\"] }\n",
        "        sample_prompt_arguments.update( {all.get(\"sample_every_n_type\"):all.get(\"sample_every_n_type_value\")} )\n",
        "\n",
        "        #dreambooth_arguments部分\n",
        "        dreambooth_arguments = { key: all.get(key) for key in [\"train_data_dir\", \"reg_data_dir\", \"prior_loss_weight\"] }\n",
        "\n",
        "        #saving_arguments部分\n",
        "        saving_arguments = { key: all.get(key) for key in [\"output_dir\",\\\n",
        "                                      \"output_name\", \"save_every_n_epochs\", \"save_n_epoch_ratio\",\\\n",
        "                                      \"save_last_n_epochs\", \"save_state\", \"save_model_as\" ]\n",
        "        }\n",
        "        \"\"\" 指定log输出目录与output相同 \"\"\"\n",
        "        saving_arguments.update( { \"logging_dir\":os.path.join( all.get(\"output_dir\"), \"logs\" ) } )\n",
        "        \"\"\" 指定log前缀和输出名字相同 \"\"\"\n",
        "        saving_arguments.update( { \"log_prefix\":all.get(\"output_name\") } )\n",
        "        \n",
        "\n",
        "        toml_dict = {\"model_arguments\":model_arguments,\n",
        "               \"additional_network_arguments\":additional_network_arguments,\n",
        "               \"optimizer_arguments\":optimizer_arguments,\n",
        "               \"dataset_arguments\":dataset_arguments,\n",
        "               \"training_arguments\":training_arguments,\n",
        "               \"sample_prompt_arguments\":sample_prompt_arguments,\n",
        "               \"dreambooth_arguments\":dreambooth_arguments,\n",
        "               \"saving_arguments\":saving_arguments,\n",
        "        }\n",
        "        toml_str = toml.dumps(toml_dict)\n",
        "        return toml_str\n",
        "    def sample_parameter2txt():\n",
        "        #key_list = [\"prompt\", \"negative\", \"sample_width\", \"sample_height\", \"sample_scale\", \"sample_steps\", \"sample_seed\"]\n",
        "        sample_str = f\"\"\"{all.get(\"prompt\")}  \\\n",
        "--n {all.get(\"negative\")}  \\\n",
        "--w {all.get(\"sample_width\")}  \\\n",
        "--h {all.get(\"sample_height\")}  \\\n",
        "--l {all.get(\"sample_scale\")}  \\\n",
        "--s {all.get(\"sample_steps\")}  \\\n",
        "{f\"--d {all.get('sample_seed')}\" if all.get('sample_seed') > 0 else \"\"}\"\"\"\n",
        "\n",
        "        return sample_str\n",
        "\n",
        "    def write(content, path):\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(content)\n",
        "\n",
        "    write(parameter2toml(), config_file_toml_path)\n",
        "    write(sample_parameter2txt(), sample_prompts_txt_path)\n",
        "    write_files_title = f\"写入成功,输出文件在{write_files_dir}：config_file.toml和sample_prompts.txt\"\n",
        "    return write_files_title\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        write_files_button = gr.Button(\"生成toml参数与采样配置文件\")\n",
        "        all_parameter_get_button = gr.Button(\"全部参数确认\")\n",
        "        write_files_dir = gr.Textbox(lines=1, label=\"写入文件夹\", placeholder=\"文件夹路径,不填就默认为当前文件夹\", value=\"\")\n",
        "    write_files_title = gr.Markdown(\"生成适用于kohya/train_network.py的配置文件\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"基础参数\"):\n",
        "            common_parameter_get_button = gr.Button(\"确定\")\n",
        "            common_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"当前基础参数配置\", open=False):\n",
        "                common_parameter_toml = gr.Textbox(label=\"toml形式\", placeholder=\"基础参数\", value=\"\")\n",
        "            with gr.Row():\n",
        "                train_data_dir = gr.Textbox(lines=1, label=\"train_data_dir\", placeholder=\"训练集路径\")\n",
        "            with gr.Accordion(\"使用正则化(可选)\", open=False):\n",
        "                with gr.Row():\n",
        "                    reg_data_dir = gr.Textbox(lines=1, label=\"reg_data_dir\", placeholder=\"正则化集路径（填入意味着启用正则化）\")\n",
        "                    prior_loss_weight = gr.Slider(0, 1, step=0.01, value=0.3, label=\"正则化权重\")\n",
        "            with gr.Row():\n",
        "                base_model_dir = gr.Textbox(label=\"底模文件夹地址\", placeholder=\"文件夹路径,不填就默认为当前文件夹\")\n",
        "                base_model_get_button = gr.Button(reuse_symbol)\n",
        "                base_model_name = gr.Dropdown(choices=[],label=\"底模\",value=\"\")\n",
        "            with gr.Accordion(\"使用vae(可选)\", open=False):\n",
        "                with gr.Row():\n",
        "                    vae_model_dir = gr.Textbox(label=\"vae文件夹地址\", placeholder=\"文件夹路径,不填就默认为当前文件夹\")\n",
        "                    vae_model_get_button = gr.Button(reuse_symbol)\n",
        "                    vae_model_name = gr.Dropdown(choices=[],label=\"vae\",value=\"\")\n",
        "                    use_vae = gr.Checkbox(label=\"是否使用vae\",value=False)\n",
        "            with gr.Row():\n",
        "                width = gr.Slider(64, 1920, step=64, value=512, label=\"训练分辨率（宽）width\")\n",
        "                height = gr.Slider(64, 1920, step=64, value=512, label=\"训练分辨率（高）height\")\n",
        "                batch_size = gr.Slider(1, 24, step=1, value=1, label=\"batch大小\")\n",
        "            with gr.Row():\n",
        "                noise_offset = gr.Slider(0, 1, step=0.01, value=0.05, label=\"noise_offset\")\n",
        "                keep_tokens = gr.Slider(0, 225, step=1, value=0, label=\"keep_tokens\")\n",
        "                min_snr_gamma = gr.Slider(0, 100, step=0.1, value=5, label=\"min_snr_gamma`设置为0则不生效`\")\n",
        "            \"\"\"\n",
        "            with gr.Row():\n",
        "                gr.Markdown(\"repeat * 图片数 = 每个epoch的steps数\")\n",
        "            \"\"\"\n",
        "            with gr.Row():\n",
        "                max_train_method = gr.Dropdown([\"max_train_epochs\",\"max_train_steps\"], label=\"以epochs或steps来指定最大训练时间\", value=\"max_train_epochs\")\n",
        "                max_train_value = gr.Number(label=\"最大训练epochs\\steps数\", value=10, precision=0)\n",
        "            with gr.Accordion(\"输出设置\", open=True):\n",
        "                with gr.Row():\n",
        "                    output_dir = gr.Textbox( label=\"模型、log日志输出地址（自行修改）\", placeholder=\"文件夹路径\",value=os.path.join(os.getcwd(),\"output\") )\n",
        "                    output_name = gr.Textbox(label=\"输出模型名称（自行修改）\", placeholder=\"名称\",value=\"output_name\")\n",
        "                    save_model_as = gr.Dropdown([\"safetensors\",\"ckpt\",\"pt\"], label=\"保存模型格式\", value=\"safetensors\")\n",
        "                with gr.Row():\n",
        "                    save_every_n_epochs = gr.Slider(1, 499, step=1, value=1, label=\"每n个epoch保存一次\")\n",
        "                    save_n_epoch_ratio = gr.Slider(1, 499, step=1, value=0, label=\"等间隔保存n个(如不指定为0，将会覆盖每n个epoch保存一次)\")\n",
        "                    save_last_n_epochs = gr.Slider(1, 499, step=1, value=499, label=\"最多保存n个（后面的出来就会把前面删了,优先级最高）\")\n",
        "                    save_state = gr.Checkbox(label=\"保存学习状态\",value=False)\n",
        "            with gr.Row():\n",
        "                optimizer_type = gr.Dropdown([\"AdamW8bit\", \"Lion\", \"DAdaptation\", \"AdamW\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"],\\\n",
        "                                label=\"optimizer_type优化器类型\", value=\"AdamW8bit\")\n",
        "                unet_lr = gr.Number(label=\"unet学习率\", value=1e-4)\n",
        "                text_encoder_lr = gr.Number(label=\"text_encoder学习率\", value=1e-5)\n",
        "            with gr.Row():\n",
        "                lr_scheduler = gr.Dropdown([\"cosine_with_restarts\",\"cosine\",\"polynomial\",\"linear\",\"constant_with_warmup\",\"constant\"],\\\n",
        "                               label=\"lr_scheduler学习率调度器\", value=\"cosine_with_restarts\")\n",
        "                lr_warmup_steps = gr.Number(label=\"升温步数\", value=0, precision=0)\n",
        "                lr_restart_cycles = gr.Number(label=\"退火重启次数\", value=1, precision=0)\n",
        "            with gr.Row():\n",
        "                train_method = gr.Dropdown([\"LoRA-LierLa\", \"LoRA-C3Lier\",\\\n",
        "                                \"LoCon_Lycoris\",\"LoHa_Lycoris\",\\\n",
        "                                \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"],\\\n",
        "                                label=\"train_method训练方法\", value=\"LoRA-LierLa\")\n",
        "                network_dim = gr.Number(label=\"线性dim\", value=32, precision=0)\n",
        "                network_alpha = gr.Number(label=\"线性alpha（可以为小数）\", value=16)\n",
        "            with gr.Accordion(\"额外网络参数(LoRA-C3Lier、LoCon、LoHa、DyLoRa-C3Lier都属于卷积,unit为两个DyLoRa专用)\", open=True):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        conv_dim = gr.Number(label=\"卷积dim\", info=\"使用DyLoRa-C3Lier时会被设置为等于基础dim\", value=8, precision=0)\n",
        "                    with gr.Column():\n",
        "                        conv_alpha = gr.Number(label=\"卷积alpha\", info=\"可以为小数\", value=1)\n",
        "                    with gr.Column():\n",
        "                        unit = gr.Number(label=\"分割单位unit(整数)\", info=\"使用DyLoRa时，请让dim为unit的倍数\", value=1, precision=0)\n",
        "            with gr.Row():          \n",
        "                v2 = gr.Checkbox(label=\"v2\")\n",
        "                v_parameterization = gr.Checkbox(label=\"v_parameterization\")\n",
        "                lowram = gr.Checkbox(label=\"lowram\")\n",
        "                xformers = gr.Checkbox(label=\"xformers\",value=True)\n",
        "        with gr.TabItem(\"采样参数\"):\n",
        "            sample_parameter_get_button = gr.Button(\"确定\")\n",
        "            sample_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"当前采样配置\", open=False):\n",
        "                sample_parameter_toml = gr.Textbox(label=\"toml形式\", placeholder=\"采样配置\", value=\"\")\n",
        "            with gr.Row():\n",
        "                #enable_sample = gr.Checkbox(label=\"是否启用采样功能\")\n",
        "                sample_every_n_type = gr.Dropdown([\"sample_every_n_epochs\", \"sample_every_n_steps\"], label=\"sample_every_n_type\", value=\"sample_every_n_epochs\")\n",
        "                sample_every_n_type_value = gr.Number(label=\"sample_every_n_type_value\", value=1, precision=0)\n",
        "            with gr.Row():\n",
        "                sample_sampler = gr.Dropdown([\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\",\\\n",
        "                            \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\",\\\n",
        "                            \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"],\\\n",
        "                            label=\"采样器\", value=\"euler_a\")\n",
        "                sample_width = gr.Slider(64, 1920, step=64, value=512, label=\"采样图片宽\")\n",
        "                sample_height = gr.Slider(64, 1920, step=64, value=768, label=\"采样图片高\")\n",
        "                sample_scale = gr.Slider(1, 30, step=0.5, value=7, label=\"提示词相关性\")\n",
        "                sample_seed = gr.Number(label=\"采样种子(-1不是随机，大于0才生效)\", value=-1, precision=0)\n",
        "                sample_steps = gr.Slider(1, 150, step=1, value=24, label=\"采样迭代步数\")\n",
        "            with gr.Row():\n",
        "                prompt = gr.Textbox(lines=10, label=\"prompt\", placeholder=\"正面提示词\", value=\"(masterpiece, best quality, hires:1.2), 1girl, solo,\")\n",
        "                default_negative = (\"(worst quality, bad quality:1.4), \"\n",
        "                          \"lowres, bad anatomy, bad hands, text, error, \"\n",
        "                          \"missing fingers, extra digit, fewer digits, \"\n",
        "                          \"cropped, worst quality, low quality, normal quality, \"\n",
        "                          \"jpeg artifacts,signature, watermark, username, blurry,\")\n",
        "                negative = gr.Textbox(lines=10, label=\"negative\", placeholder=\"负面提示词\", value=default_negative)\n",
        "        with gr.TabItem(\"进阶参数\"):\n",
        "            plus_parameter_get_button = gr.Button(\"确定\")\n",
        "            plus_parameter_title = gr.Markdown(\"\")\n",
        "            with gr.Accordion(\"当前进阶参数配置\", open=False):\n",
        "                plus_parameter_toml = gr.Textbox(label=\"toml形式\", placeholder=\"进阶参数\", value=\"\")\n",
        "            with gr.Row():\n",
        "                use_retrain = gr.Dropdown([\"no\",\"model\",\"state\"], label=\"是否使用重训练\", value=\"no\")\n",
        "                retrain_dir = gr.Textbox(lines=1, label=\"重训练路径\", placeholder=\"模型或者状态路径\", value=\"\")\n",
        "            with gr.Row():\n",
        "                min_bucket_reso = gr.Slider(64, 1920, step=64, value=256, label=\"最低桶分辨率\")\n",
        "                max_bucket_reso = gr.Slider(64, 1920, step=64, value=1024, label=\"最高桶分辨率\")\n",
        "                clip_skip = gr.Slider(0, 25, step=1, value=2, label=\"跳过层数\")\n",
        "                caption_extension = gr.Textbox(lines=1, label=\"标签文件扩展名\", placeholder=\"一般填.txt或.cap\", value=\".txt\")\n",
        "                max_token_length = gr.Slider(75, 225, step=75, value=225, label=\"训练最大token数\")\n",
        "                seed = gr.Number(label=\"种子\", value=1337, precision=0)\n",
        "            with gr.Row():\n",
        "                network_train_unet_only= gr.Checkbox(label=\"仅训练unet网络\",value=False)\n",
        "                network_train_text_encoder_only = gr.Checkbox(label=\"仅训练text_encoder网络\",value=False)\n",
        "            with gr.Accordion(\"分层学习模块\", open=True):\n",
        "                gr.Markdown(\"学习率分层，为不同层的结构指定不同学习率倍数\")\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=15):\n",
        "                        up_lr_weight = gr.Textbox(lines=1, label=\"上层学习率权重\", placeholder=\"留空则不启用\",\\\n",
        "                                      info=\"15层，例如1.5,1.5,1.5,1.5,1.0,1.0,1.0,1.0,0.5,0.5,0.5,0.5\", value=\"\")\n",
        "                    with gr.Column(scale=1):\n",
        "                        mid_lr_weight = gr.Textbox(lines=1, label=\"中层学习率权重\", placeholder=\"留空则不启用\",\\\n",
        "                                      info=\"1层，例如2.0\", value=\"\")\n",
        "                    with gr.Column(scale=15):\n",
        "                        down_lr_weight = gr.Textbox(lines=1, label=\"下层学习率权重\", placeholder=\"留空则不启用\",\\\n",
        "                                      info=\"15层，例如0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0,1.5,1.5,1.5,1.5\", value=\"\")\n",
        "                gr.Markdown(\"dim和alpha分层，为不同层的结构指定不同的dim和alpha（`DyLoRa`无法使用，卷积分层只有`LoRa-C3Lier、LoCon、LoHa`可以使用）\")\n",
        "                with gr.Row():\n",
        "                        block_dims = gr.Textbox(lines=1, label=\"线性dim分层\", placeholder=\"留空则不启用\",\\\n",
        "                                      info=\"25层（上中下），例如2,4,4,4,8,8,8,8,12,12,12,12,16,12,12,12,12,8,8,8,8,4,4,4,2\", value=\"\")\n",
        "                        block_alphas = gr.Textbox(lines=1, label=\"线性alpha分层\", placeholder=\"留空则不启用\",\\\n",
        "                                      info=\"25层（上中下），例如2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "                with gr.Row():\n",
        "                        conv_block_dims = gr.Textbox(lines=1, label=\"卷积dim分层\", placeholder=\"留空则不启用\",\\\n",
        "                                        info=\"25层（上中下），例如2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "                        conv_block_alphas = gr.Textbox(lines=1, label=\"卷积alpha分层\", placeholder=\"留空则不启用\",\\\n",
        "                                        info=\"25层（上中下），例如2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n",
        "\n",
        "\n",
        "    def dict_key_list_2_list(dict_key_list):\n",
        "        list = []\n",
        "        for key in dict_key_list:\n",
        "            try:\n",
        "                list.append(globals()[key])\n",
        "            except KeyError:\n",
        "                print(f\"Error: parameter_dict_key_list中{key}不存在\")\n",
        "        list_len = len(list)\n",
        "        return list, list_len\n",
        "\n",
        "    common_parameter_dict_key_list = [\"train_data_dir\",\n",
        "                      \"reg_data_dir\",\n",
        "                      \"prior_loss_weight\",\n",
        "                      \"base_model_dir\",\n",
        "                      \"base_model_name\",\n",
        "                      \"vae_model_dir\",\n",
        "                      \"vae_model_name\",\n",
        "                      \"use_vae\",\n",
        "                      \"width\",\n",
        "                      \"height\",\n",
        "                      \"batch_size\",\n",
        "                      \"noise_offset\",\n",
        "                      \"keep_tokens\",\n",
        "                      \"min_snr_gamma\",\n",
        "                      \"max_train_method\",\n",
        "                      \"max_train_value\",\n",
        "                      \"output_dir\",\n",
        "                      \"output_name\",\n",
        "                      \"save_model_as\",\n",
        "                      \"save_every_n_epochs\",\n",
        "                      \"save_n_epoch_ratio\",\n",
        "                      \"save_last_n_epochs\",\n",
        "                      \"save_state\",\n",
        "                      \"optimizer_type\",\n",
        "                      \"unet_lr\",\n",
        "                      \"text_encoder_lr\",\n",
        "                      \"lr_scheduler\",\n",
        "                      \"lr_warmup_steps\",\n",
        "                      \"lr_restart_cycles\",\n",
        "                      \"train_method\",\n",
        "                      \"network_dim\",\n",
        "                      \"network_alpha\",\n",
        "                      \"conv_dim\",\n",
        "                      \"conv_alpha\",\n",
        "                      \"unit\",\n",
        "                      \"v2\",\n",
        "                      \"v_parameterization\",\n",
        "                      \"lowram\",\n",
        "                      \"xformers\"]\n",
        "    common_parameter_list, parameter_len_dict[\"common\"] = dict_key_list_2_list(common_parameter_dict_key_list)\n",
        "    sample_parameter_dict_key_list = [\"sample_every_n_type\",\n",
        "                      \"sample_every_n_type_value\",\n",
        "                      \"sample_sampler\",\n",
        "                      \"sample_width\",\n",
        "                      \"sample_height\",\n",
        "                      \"sample_scale\",\n",
        "                      \"sample_seed\",\n",
        "                      \"sample_steps\",\n",
        "                      \"prompt\",\n",
        "                      \"negative\"]\n",
        "    sample_parameter_list, parameter_len_dict[\"sample\"] = dict_key_list_2_list(sample_parameter_dict_key_list)\n",
        "    plus_parameter_dict_key_list = [\"use_retrain\",\n",
        "                    \"retrain_dir\",\n",
        "                    \"min_bucket_reso\",\n",
        "                    \"max_bucket_reso\",\n",
        "                    \"clip_skip\",\n",
        "                    \"caption_extension\",\n",
        "                    \"max_token_length\",\n",
        "                    \"seed\",\n",
        "                    \"network_train_unet_only\",\n",
        "                    \"network_train_text_encoder_only\",\n",
        "                    \"up_lr_weight\",\n",
        "                    \"mid_lr_weight\",\n",
        "                    \"down_lr_weight\",\n",
        "                    \"block_dims\",\n",
        "                    \"block_alphas\",\n",
        "                    \"conv_block_dims\",\n",
        "                    \"conv_block_alphas\"]\n",
        "    plus_parameter_list, parameter_len_dict[\"plus\"] = dict_key_list_2_list(plus_parameter_dict_key_list)\n",
        "    all_parameter_list = common_parameter_list + sample_parameter_list + plus_parameter_list\n",
        "\n",
        "    common_parameter_get_button.click(fn=common_parameter_get,\n",
        "                    inputs=common_parameter_list,\n",
        "                    outputs=[common_parameter_toml,  common_parameter_title]\n",
        "                    )\n",
        "    sample_parameter_get_button.click(fn=sample_parameter_get,\n",
        "                    inputs=sample_parameter_list,\n",
        "                    outputs=[sample_parameter_toml,  sample_parameter_title]\n",
        "                    )\n",
        "    plus_parameter_get_button.click(fn=plus_parameter_get,\n",
        "                    inputs=plus_parameter_list,\n",
        "                    outputs=[plus_parameter_toml,  plus_parameter_title]\n",
        "                    )\n",
        "    all_parameter_get_button.click(fn=all_parameter_get,\n",
        "                    inputs=all_parameter_list,\n",
        "                    outputs=[common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  write_files_title]\n",
        "                    )\n",
        "    base_model_get_button.click(fn=model_get,inputs=base_model_dir,outputs=[base_model_dir, base_model_name])\n",
        "    vae_model_get_button.click(fn=model_get,inputs=vae_model_dir,outputs=[vae_model_dir, vae_model_name])\n",
        "    write_files_button.click(fn=write_files, inputs=[write_files_dir], outputs=[write_files_title])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=False,inbrowser=False,inline=True,debug=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6ikbBvFSRQ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 安装依赖环境\n",
        "\n",
        "\n",
        "\n",
        "#install python 3.10 安装py3.10\n",
        "!sudo apt-get update -y > /dev/null 2>&1\n",
        "!sudo apt-get install python3.10 > /dev/null 2>&1\n",
        "#change alternatives 首选py3.9\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1  > /dev/null 2>&1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2  > /dev/null 2>&1\n",
        "#check python version 查看版本 #3.10\n",
        "!python --version\n",
        "print(\"python升级中\")\n",
        "# install pip for new python 为py3.10安装pip\n",
        "!sudo apt-get install python3.10-distutils  > /dev/null 2>&1\n",
        "!wget https://bootstrap.pypa.io/get-pip.py  > /dev/null 2>&1\n",
        "!python get-pip.py  > /dev/null 2>&1\n",
        "#install colab's dependencies 安装colab依赖\n",
        "!python -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor  > /dev/null 2>&1\n",
        "# link to the old google package 将py3.9的谷歌依赖连接至3.10\n",
        "!ln -s /usr/local/lib/python3.9/dist-packages/google \\\n",
        "/usr/local/lib/python3.10/dist-packages/google  > /dev/null 2>&1\n",
        "print(\"python升级完成\")\n",
        "\n",
        "###################################################################################\n",
        "#安装相关环境\n",
        "\n",
        "\n",
        "\n",
        "#安装其他依赖\n",
        "print(f\"其他依赖安装中，此步耗时较长，请耐心等待\")\n",
        "%cd sd-scripts\n",
        "!pip -q install --upgrade -r requirements.txt\n",
        "print(f\"其他依赖安装完成\")\n",
        "\n",
        "#安装xformers 0.0.16版本\n",
        "print(f\"xformers安装中\")\n",
        "!pip -q install xformers==0.0.17\n",
        "print(f\"xformers-0.0.17安装完成\")\n",
        "\n",
        "#安装Triton\n",
        "print(f\"triton安装中\")\n",
        "!pip -q install triton==2.0.0\n",
        "print(f\"Triton安装完成\")\n",
        "\n",
        "#安装lion优化器、lycoris\n",
        "print(f\"lion优化器、lycoris安装中\")\n",
        "!pip -q install --upgrade lion-pytorch lycoris-lora\n",
        "print(f\"lion优化器、lycoris安装完成\")\n",
        "\n",
        "#安装Dadaption优化器\n",
        "print(f\"Dadaption优化器安装中\")\n",
        "!pip -q install dadaptation\n",
        "print(f\"Dadaption优化器安装完成\")\n",
        "\n",
        "\n",
        "#############################\n",
        "#开启tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mxO7gAHILhZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （三）开始训练"
      ],
      "metadata": {
        "id": "pYZtXvtmes2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  ### 开始训练\n",
        "\n",
        "#@markdown 若正确运行，训练完成后，模型会自动保存至你在WebUI里设置的地址\n",
        "\n",
        "#开始训练！\n",
        "%cd /content/sd-scripts\n",
        "!export TF_CPP_MIN_LOG_LEVEL=3\n",
        "!accelerate launch --num_cpu_threads_per_process 8 train_network.py --config_file=\"config_file.toml\" --sample_prompts=\"sample_prompts.txt\" \n",
        "\n",
        "\n",
        "!echo \"完成了 XXXD.\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "NTRgMI7jR3DY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}